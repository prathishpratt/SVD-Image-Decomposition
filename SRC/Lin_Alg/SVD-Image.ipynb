{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc8deb71-def6-49ba-8dac-81f179d6eab1",
   "metadata": {},
   "source": [
    "## Image Compression using Singular Value Decomposition and comparison with SOTA method\n",
    "\n",
    "**Course:** DSC210: Numerical Linear Algebra for Data Science\n",
    "\n",
    "**Instructor:** Dr. Tsui-wei Weng\n",
    "\n",
    "**Group number:** 4\n",
    "\n",
    "**Group topic:** Topic 11: CV/image processing-related\n",
    "\n",
    "\n",
    "**Group members:**\n",
    "\n",
    "*   Dinesh Karthikeyan\n",
    "*   Nandita Sanjivi\n",
    "*   Prathish Murugan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11b00b3-5cc8-4566-b79b-7b5bb6c40bfa",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d86ba63d-46e5-4978-939c-dc9f1aae0748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-25 22:37:32.636235: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2023-11-25 22:37:32.636271: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2023-11-25 22:37:32.636280: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2023-11-25 22:37:32.636612: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-11-25 22:37:32.637048: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# To run M1 GPU, SKIP IF NOT NEEDEED\n",
    "\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.print(physical_devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "190c534d-45a7-4dc0-aef3-2f5a8bdb531d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print('GPU is available')\n",
    "else:\n",
    "    print('GPU is NOT available')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d3e1a-5b3c-4280-a343-a2aedad87993",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "617f9cc4-a472-455a-abf0-8cfa96f82f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os                                                                # Access File path \n",
    "import imageio                                                           # To build GIF\n",
    "import ipywidgets as widgets                                             # For Slider Widgets\n",
    "from numpy.linalg import svd                                             # To perform SVD\n",
    "from PIL import Image                                                    # Imaging Library\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from ipywidgets import interact, interactive, interact_manual\n",
    "from IPython.display import display\n",
    "from skimage.io import imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fff0f227-7d32-4b24-8de0-40d28caa92c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.Evaluation_metric import get_mse, ssim_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44711bda-7e54-4867-ace9-3cdd46e720fc",
   "metadata": {},
   "source": [
    "## Color Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab9e47ce-e1f0-4a66-ba41-bda5722b2438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the image\n",
    "\n",
    "images = {\n",
    "    \"Geisel\": np.asarray(Image.open('Images/Geisel.webp')),        #Notice different image formats for images\n",
    "    \"Iphone\": np.asarray(Image.open('Images/Iphone.jpeg')),\n",
    "    \"Flower\": np.asarray(Image.open('Images/Flower.png')),\n",
    "    \"Tamil_food\": np.asarray(Image.open('Images/Tamil_food.jpeg')),\n",
    "    \"Cliffs\": np.asarray(Image.open('Images/Cliffs.jpeg')),\n",
    "    \"Henry\": np.asarray(Image.open('Images/Henry.jpeg')),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c21d4082-a750-49ea-b342-7842dd2b12ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7662aad93ce444b0b59ef43a8d948104",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='img_name', options=('Geisel', 'Iphone', 'Flower', 'Tamil_food', 'Câ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.show_images(img_name)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the images\n",
    "\n",
    "def show_images(img_name):\n",
    "    \n",
    "    'It will show image in widget'\n",
    "    \n",
    "    plt.title(\"Image Name: \"+img_name+\"\\n\")\n",
    "    plt.imshow(images[img_name])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "interact(show_images, img_name=list(images.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eaac05e3-7a1b-4526-b67f-33059ecd9a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compressed_image = None\n",
    "# text = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a8b16c7-d69c-4dfa-8879-684279bf3378",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the image channels into R, G & B \n",
    "\n",
    "def split_channel(pic_rgb):\n",
    "    '''\n",
    "    Split the image channels into R, G & B \n",
    "    '''\n",
    "    pic_r = pic_rgb[:, :, 0]                      # Red channel\n",
    "    pic_g = pic_rgb[:, :, 1]                      # Green channel\n",
    "    pic_b = pic_rgb[:, :, 2]                      # Blue channel\n",
    "\n",
    "    return pic_r, pic_g, pic_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20e63c9d-2776-494c-9efc-2f9fe23cfa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sv_decompose(r,g,b,k,shape):\n",
    "    '''\n",
    "    Function to perform SVD and then reconstruct the image for k component\n",
    "    '''\n",
    "    \n",
    "    ur,sr,vr = svd(r, full_matrices=False)        # SVD on Red Channel\n",
    "    ug,sg,vg = svd(g, full_matrices=False)        # SVD on Green Channel\n",
    "    ub,sb,vb = svd(b, full_matrices=False)        # SVD on Blue Channel\n",
    "    \n",
    "    rr = np.dot(ur[:,:k],np.dot(np.diag(sr[:k]), vr[:k,:]))    # Reconstructing the Image with different k parameter for red\n",
    "    rg = np.dot(ug[:,:k],np.dot(np.diag(sg[:k]), vg[:k,:]))    # Reconstructing the Image with different k parameter for green\n",
    "    rb = np.dot(ub[:,:k],np.dot(np.diag(sb[:k]), vb[:k,:]))    # Reconstructing the Image with different k parameter for blue\n",
    "\n",
    "    rimg = np.zeros(shape)    #Create an array of the image's shape so that we can impose the reconstructed channels\n",
    "    rimg[:,:,0] = rr\n",
    "    rimg[:,:,1] = rg\n",
    "    rimg[:,:,2] = rb\n",
    "\n",
    "    return rimg               # Return an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b20a2af-ccfb-467a-baa7-5779e142481b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(compressed_image,img_name):\n",
    "    '''\n",
    "    To show the image in a widget mode\n",
    "    '''\n",
    "    \n",
    "    plt.title(\"Image Name: \"+img_name+\"\\n\")\n",
    "    plt.imshow(compressed_image)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    compressed_image = Image.fromarray(compressed_image)\n",
    "    \n",
    "    text = widgets.Text(value=\"image_save\",placeholder='Enter image name...',description='Image name')\n",
    "    display(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e91726d-b458-4cdf-81c5-fa2f5db39d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_image(img_name, k):\n",
    "    '''\n",
    "    Function to compress and clip the image\n",
    "    '''\n",
    "    global text\n",
    "    global compressed_image\n",
    "    img = images[img_name]\n",
    "\n",
    "    r,g,b = split_channel(img)\n",
    "\n",
    "    print(\"compressing...\")\n",
    "    print(\"Use the Slider for different k values\")\n",
    "\n",
    "    rimg = sv_decompose(r,g,b,k,img.shape)\n",
    "\n",
    "    rimg = np.clip(np.abs(rimg), 0, 255) \n",
    "    #if an interval of [0, 255] is specified, values smaller than 0 become 0, and values larger than 255 become 255\n",
    "    #the absolute value of each element in the image and then uses \"clip\" to make the values are within the range [0, 255]. \n",
    "\n",
    "    compressed_image = rimg.astype(np.uint8)\n",
    "\n",
    "    print(\"MSE between compressed image and original image is: \", get_mse(compressed_image ,img))\n",
    "    print(\"SSIM between compressed image and original image is: \", ssim_k(compressed_image, img))\n",
    "    show_img(compressed_image,img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d16962d-8e54-432b-b641-d3df94f1f4ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46ccdc67b94741e19177a82aab4d7800",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='img_name', options=('Geisel', 'Iphone', 'Flower', 'Tamil_food', 'Câ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.compress_image(img_name, k)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Call the widget\n",
    "interact(compress_image, img_name=list(images.keys()), k = (0,200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76a7cffb-7e9b-4954-8630-00109a4547a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat the same functions as above, just to create a GIF\n",
    "\n",
    "pic_rgb = imread('Images/Geisel.webp')\n",
    "\n",
    "pic_r = pic_rgb[:, :, 0]\n",
    "pic_g = pic_rgb[:, :, 1]\n",
    "pic_b = pic_rgb[:, :, 2]\n",
    "\n",
    "# SVD decomposition for Red, Green and Blue\n",
    "U_r, s_r, VT_r = svd(pic_r, full_matrices=False)\n",
    "U_g, s_g, VT_g = svd(pic_g, full_matrices=False)\n",
    "U_b, s_b, VT_b = svd(pic_b, full_matrices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14c3d2fb-d7a3-4a22-95ad-9aed3c00c761",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = []\n",
    "for r in np.arange(60, 0, -1):\n",
    "    # r is the number of singular values used\n",
    "\n",
    "    # Restoring the image\n",
    "    pic_reduce_r = U_r[:, :r] @ np.diag(s_r[:r]) @ VT_r[:r, :]\n",
    "    pic_reduce_g = U_g[:, :r] @ np.diag(s_g[:r]) @ VT_g[:r, :]\n",
    "    pic_reduce_b = U_b[:, :r] @ np.diag(s_b[:r]) @ VT_b[:r, :]\n",
    "\n",
    "    pic_reduce_rgb = np.stack(\n",
    "        [pic_reduce_r, pic_reduce_g, pic_reduce_b], axis=2)\n",
    "    # Crop values to the range [0, 255]\n",
    "    pic_reduce_rgb[pic_reduce_rgb < 0.] = 0\n",
    "    pic_reduce_rgb[pic_reduce_rgb > 255.] = 255\n",
    "\n",
    "    plt.imshow(pic_reduce_rgb.astype('uint8'))\n",
    "    plt.axis('off')\n",
    "    plt.savefig(str(r) + '.png')\n",
    "\n",
    "    name = f'{r}.png'\n",
    "    filenames.append(name)\n",
    "\n",
    "    # save frame\n",
    "    plt.savefig(name)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94a0167b-4907-4dc8-a32a-f7eb01644652",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/50/x3m5nv1558v3d78g8w5wff2m0000gn/T/ipykernel_68611/2278178019.py:4: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  image = imageio.imread(name)\n"
     ]
    }
   ],
   "source": [
    "# build gif\n",
    "with imageio.get_writer('SVD.gif', mode='I') as writer:\n",
    "    for name in filenames:\n",
    "        image = imageio.imread(name)\n",
    "        writer.append_data(image)\n",
    "\n",
    "# Remove files\n",
    "for name in set(filenames):\n",
    "    os.remove(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee335bc0-5481-412c-bb05-b58acd853f49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
